{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdecb6fb",
   "metadata": {},
   "source": [
    "Trying the pickle add function but does not function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cdd4f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:41:03.659522Z",
     "start_time": "2022-04-10T19:40:47.671344Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:40:52.902704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/anthony/.pyenv/versions/3.8.12/envs/tails-and-whales/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-04-10 21:40:52.902876: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f966f812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:50:41.389879Z",
     "start_time": "2022-04-10T19:50:41.338043Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_X_y(number_of_photos, csv_path = '../raw_data/train_kaggle.csv'): #number of photos could be a parameter\n",
    "    # load and make changes to csv  \n",
    "    data = pd.read_csv(csv_path)\n",
    "    data['speciesv2'] = data['species']\n",
    "    data['speciesv2'].loc[data['speciesv2'].str.contains('dolphin')] = 'dolphin'\n",
    "    data['speciesv2'].loc[data['speciesv2'].str.contains('dolpin')] = 'dolphin'\n",
    "    data['speciesv2'].loc[data['speciesv2'].str.contains('whale')] = 'whale'\n",
    "    data = data[data['speciesv2'] != 'globis']\n",
    "    # create and save X in raw-data/X.pkl\n",
    "    path = \"../raw_data/train_images/\"\n",
    "    images_list = list(data['image'])\n",
    "\n",
    "    # This block code includes a resizing step\n",
    "    loaded_images = []\n",
    "    a = 1\n",
    "    for index, image in enumerate(images_list[:number_of_photos]):   #number of photos [:number_of_photos]\n",
    "        print(f\" processing photo number {a}\")\n",
    "\n",
    "        # resizing image\n",
    "        img = mpimg.imread(path + image)\n",
    "        img = cv2.resize(img, dsize=(256, 256), interpolation= cv2.INTER_LINEAR)\n",
    "        a +=1\n",
    "\n",
    "        # reshaphe photo in 3D dimension\n",
    "        if len(img.shape) != 3:\n",
    "            #list_index_bw.append(index)\n",
    "            #list_len.append(len(img.shape))\n",
    "            img = np.stack((img,)*3, axis=-1)\n",
    "\n",
    "        loaded_images.append(np.array(img))    \n",
    "  \n",
    "    # convert to 3D array\n",
    "    X = np.array(loaded_images)\n",
    "    print(X.shape)\n",
    "    # get gcp bucket path\n",
    "\n",
    "    preprocessed_data_path = \"../raw_data/preprocessed_data/\"\n",
    "    # save preprocessed images to GCP bucket\n",
    "    with open(os.path.join(preprocessed_data_path, 'X_1.pkl'), 'ab') as handle:\n",
    "        pickle.dump(X, handle)\n",
    "       \n",
    "    # create and save y in raw_data/y.pkl\n",
    "    classes = {'whale':0, 'dolphin':1, 'beluga':2}\n",
    "    #Add a new column 'class' on data_sample df\n",
    "    data['class'] = data['speciesv2'].map(classes)\n",
    "    num_classes = 3\n",
    "    y = to_categorical(data['class'][:number_of_photos], num_classes=num_classes) #number of photos [:number_of_photos]\n",
    "    with open(os.path.join(preprocessed_data_path, 'y_1.pkl'), 'ab') as handle:\n",
    "        pickle.dump(y, handle)\n",
    "\n",
    "    print(\"X and y are saved ! Well Done !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02065af0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:50:43.435874Z",
     "start_time": "2022-04-10T19:50:41.888590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing photo number 1\n",
      " processing photo number 2\n",
      " processing photo number 3\n",
      " processing photo number 4\n",
      " processing photo number 5\n",
      "(5, 256, 256, 3)\n",
      "X and y are saved ! Well Done !\n"
     ]
    }
   ],
   "source": [
    "create_X_y(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d31efe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:50:46.045784Z",
     "start_time": "2022-04-10T19:50:44.403545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing photo number 1\n",
      " processing photo number 2\n",
      " processing photo number 3\n",
      " processing photo number 4\n",
      " processing photo number 5\n",
      "(5, 256, 256, 3)\n",
      "X and y are saved ! Well Done !\n"
     ]
    }
   ],
   "source": [
    "create_X_y(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a4c4189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:50:46.086900Z",
     "start_time": "2022-04-10T19:50:46.056378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 256, 256, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../raw_data/preprocessed_data/X_1.pkl\", \"rb\") as fi:\n",
    "    X = pickle.load(fi)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaaab8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:44:17.010374Z",
     "start_time": "2022-04-10T18:44:17.010087Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_X_y(number_of_photos, csv_path = '../raw_data/train_kaggle.csv'): #number of photos could be a parameter\n",
    "    # load and make changes to csv  \n",
    "    data = pd.read_csv(csv_path)\n",
    "    data['speciesv2'] = data['species']\n",
    "    data['speciesv2'].loc[data['speciesv2'].str.contains('dolphin')] = 'dolphin'\n",
    "    data['speciesv2'].loc[data['speciesv2'].str.contains('dolpin')] = 'dolphin'\n",
    "    data['speciesv2'].loc[data['speciesv2'].str.contains('whale')] = 'whale'\n",
    "    data = data[data['speciesv2'] != 'globis']\n",
    "    # create and save X in raw-data/X.pkl\n",
    "    path = \"../raw_data/train_images/\"\n",
    "    images_list = list(data['image'])\n",
    "\n",
    "    # This block code includes a resizing step\n",
    "    loaded_images = []\n",
    "    a = 1\n",
    "    for index, image in enumerate(images_list[number_of_photos:]):   #number of photos [:number_of_photos]\n",
    "        print(f\" processing photo number {a}\")\n",
    "\n",
    "        # resizing image\n",
    "        img = mpimg.imread(path + image)\n",
    "        img = cv2.resize(img, dsize=(256, 256), interpolation= cv2.INTER_LINEAR)\n",
    "        a +=1\n",
    "\n",
    "        # reshaphe photo in 3D dimension\n",
    "        if len(img.shape) != 3:\n",
    "            #list_index_bw.append(index)\n",
    "            #list_len.append(len(img.shape))\n",
    "            img = np.stack((img,)*3, axis=-1)\n",
    "\n",
    "        loaded_images.append(np.array(img))    \n",
    "  \n",
    "    # convert to 3D array\n",
    "    X = np.array(loaded_images)\n",
    "    print(X.shape)\n",
    "    # get gcp bucket path\n",
    "\n",
    "    preprocessed_data_path = \"../raw_data/preprocessed_data/\"\n",
    "    # save preprocessed images to GCP bucket\n",
    "    with open(os.path.join(preprocessed_data_path, 'X_1.pkl'), 'ab') as handle:\n",
    "        pickle.dump(X, handle)\n",
    "       \n",
    "    # create and save y in raw_data/y.pkl\n",
    "    classes = {'whale':0, 'dolphin':1, 'beluga':2}\n",
    "    #Add a new column 'class' on data_sample df\n",
    "    data['class'] = data['speciesv2'].map(classes)\n",
    "    num_classes = 3\n",
    "    y = to_categorical(data['class'][number_of_photos:], num_classes=num_classes) #number of photos [:number_of_photos]\n",
    "    with open(os.path.join(preprocessed_data_path, 'y_1.pkl'), 'ab') as handle:\n",
    "        pickle.dump(y, handle)\n",
    "\n",
    "    print(\"X and y are saved ! Well Done !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e88fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:44:17.025712Z",
     "start_time": "2022-04-10T18:44:17.025555Z"
    }
   },
   "outputs": [],
   "source": [
    "create_X_y(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf5630e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T14:38:12.802248Z",
     "start_time": "2022-04-10T14:38:12.768733Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"with open('../raw_data/preprocessed_data/X_1.npy', 'rb') as f:\n",
    "    X_1 = np.load(f)\n",
    "    \n",
    "with open('../raw_data/preprocessed_data/X_2.npy', 'rb') as g:\n",
    "    X_2 = np.load(g)\"\"\"\n",
    "    \n",
    "with open('../raw_data/preprocessed_data/y_1.npy', 'rb') as h:\n",
    "    y_1 = np.load(h)\n",
    "    \n",
    "with open('../raw_data/preprocessed_data/y_2.npy', 'rb') as i:\n",
    "    y_2 = np.load(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c0d8fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T14:38:12.828607Z",
     "start_time": "2022-04-10T14:38:12.812169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]] [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_1,y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7423cfbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T14:38:26.941955Z",
     "start_time": "2022-04-10T14:38:26.926810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50917, 3)\n"
     ]
    }
   ],
   "source": [
    "y = np.concatenate((y_1,y_2), axis=0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b026ee79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T14:39:43.865051Z",
     "start_time": "2022-04-10T14:39:43.845347Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_data_path = \"../raw_data/preprocessed_data/\"\n",
    "\n",
    "with open(os.path.join(preprocessed_data_path, 'y.npy'), 'wb') as f:\n",
    "    np.save(f, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3555f37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T14:43:41.457825Z",
     "start_time": "2022-04-10T14:43:40.971456Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63761685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T14:44:45.114421Z",
     "start_time": "2022-04-10T14:43:43.191688Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../raw_data/preprocessed_data/X_1.npy', 'rb') as f:\n",
    "    X_1 = np.load(f)\n",
    "    \n",
    "with open('../raw_data/preprocessed_data/X_2.npy', 'rb') as g:\n",
    "    X_2 = np.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07d956",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-10T14:43:44.409Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X_1,X_2), axis=0)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a6d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
